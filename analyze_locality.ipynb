{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d34b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import scipy.io\n",
    "\n",
    "from experiment import activation\n",
    "from experiment import experiment\n",
    "from experiment import michaels_load\n",
    "from experiment import mRNN\n",
    "from experiment import stim\n",
    "from experiment import utils\n",
    "\n",
    "import cpn_model\n",
    "import stim_model\n",
    "\n",
    "CUDA = None\n",
    "if isinstance(CUDA, str):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA\n",
    "    CUDA = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6551bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = experiment.get_config(stim_retain_grad=True, coadapt=False, cuda=CUDA)\n",
    "\n",
    "obs_dim, stim_dim, out_dim, cuda = cfg.unpack()\n",
    "per_mod_obs_dim = cfg.observer_instance.out_dim\n",
    "\n",
    "cpn = cpn_model.CPNModelLSTM(\n",
    "    obs_dim,\n",
    "    stim_dim,\n",
    "    num_neurons=obs_dim,\n",
    "    activation_func=cfg.cpn_activation,\n",
    "    cuda=cuda,\n",
    ")\n",
    "for param in cpn.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "mike = mRNN.MichaelsRNN(\n",
    "    init_data_path=michaels_load.get_default_path(),\n",
    "    stimulus=cfg.stim_instance,\n",
    "    cuda=CUDA\n",
    ")\n",
    "mike.set_lesion(cfg.lesion_instance)\n",
    "for param in mike.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3415fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = cfg.loader_train\n",
    "data = next(iter(dataloader))\n",
    "batch_size, trial_len, out_dim = data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29ef223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One entry for each time step\n",
    "\n",
    "din, trial_end, _, dout, labels = data\n",
    "\n",
    "def forward(cpn, din, trial_end, dout, labels, en=None):\n",
    "    stim_params = []\n",
    "    stims = []\n",
    "    preds = []\n",
    "    preds_en = []\n",
    "    mike.reset()\n",
    "    \n",
    "    cpn.reset()\n",
    "    \n",
    "    if en is not None:\n",
    "        en.reset()\n",
    "\n",
    "    # First time step: no stimulation; just priming the mRNN\n",
    "    mike_in = din[:, 0, :].T\n",
    "    mike_out = mike(mike_in)\n",
    "\n",
    "    for tidx in range(1, trial_len):\n",
    "        # Observe current activity\n",
    "        obs_raw = mike.observe(cfg.observer_instance)\n",
    "\n",
    "        brain_data = obs_raw + (trial_end[:, tidx - 1, :],)\n",
    "        cpn_in = torch.cat(brain_data, axis=1)\n",
    "\n",
    "        stims.append(mike.last_stimulus)\n",
    "        stims[-1].retain_grad()\n",
    "\n",
    "        stim = cpn(cpn_in)\n",
    "        stim_params.append(stim)\n",
    "        stim_params[-1].retain_grad()\n",
    "        \n",
    "        if en is not None:\n",
    "            # en receives (obs, stims, trial_end)\n",
    "            en_data = obs_raw + (stim_params[-1], trial_end[:, tidx - 1, :])\n",
    "            en_in = torch.cat(en_data, axis=1)\n",
    "            en_out = en(en_in)\n",
    "            \n",
    "            preds_en.append(en_out.unsqueeze(dim=1))\n",
    "\n",
    "        mike.stimulate(stim)\n",
    "\n",
    "        mike_in = din[:, tidx, :].T\n",
    "        mike_out = mike(mike_in)\n",
    "\n",
    "        preds.append(mike_out.unsqueeze(dim=1))\n",
    "    \n",
    "    return stims, stim_params, preds, preds_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade33004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for CPN training\n",
    "def lr_sched(opt, rtl, eidx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rtl - recent training loss, which we use to determine the learning rate\n",
    "        \"\"\"\n",
    "        if rtl is None or eidx < 4000:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 1e-3\n",
    "        elif rtl >= 0.008:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 1e-3\n",
    "        elif rtl >= 0.006:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 5e-4\n",
    "        elif rtl >= 0.005:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 1e-5\n",
    "        elif rtl >= 0.004:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 2e-6\n",
    "        elif rtl >= 0.0025:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 1e-6\n",
    "        else:\n",
    "            for p in opt.param_groups:\n",
    "                p[\"lr\"] = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a16233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "0 0.02537582814693451\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "1 0.02138046734035015\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "2 0.02006768248975277\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "3 0.019693749025464058\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "4 0.01915150322020054\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "5 0.018800601363182068\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "6 0.0183712225407362\n",
      "torch.Size([402, 340, 50]) torch.Size([402, 340, 1]) <built-in function len>\n",
      "7 0.017801620066165924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-09de681ea85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcpn_noisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     _, _, _, en_pred_vec = forward(\n\u001b[0m\u001b[1;32m     21\u001b[0m         cpn_noisy, din, trial_end, dout, labels, en=en)\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0b2c182f5923>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cpn, din, trial_end, dout, labels, en)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mstim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mstim_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mstim_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/co-proc/coproc-poc/cpn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# batch the computations into a single matrix multiplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We need an EN to compare to...\n",
    "# We make it, then train it.\n",
    "\n",
    "# Obs, stim, and trial end indicator (trial indicator included in obs_dim)\n",
    "en_in_dim = obs_dim + stim_dim\n",
    "en_out_dim = dout.shape[-1]\n",
    "\n",
    "en, opt = stim_model.get_stim_model(en_in_dim, en_out_dim, cuda=CUDA)\n",
    "\n",
    "rtl = 1\n",
    "eidx = 0\n",
    "\n",
    "while rtl > 0.003:\n",
    "    cpn_noisy = cpn_model.CPNNoiseyLSTMCollection(cpn, noise_var=0.1,\n",
    "                                             white_noise_pct=0.3,\n",
    "                                             white_noise_var=6,\n",
    "                                             cuda=CUDA)\n",
    "    cpn_noisy.setup(batch_size)\n",
    "    \n",
    "    _, _, _, en_pred_vec = forward(\n",
    "        cpn_noisy, din, trial_end, dout, labels, en=en)\n",
    "    \n",
    "    en_preds = torch.cat(en_pred_vec, axis=1)\n",
    "    actuals = utils.trunc_to_trial_end(en_preds, trial_end[:, :-1, :])\n",
    "    loss = torch.nn.MSELoss()(en_preds, dout[:, 1:, :])\n",
    "    loss.backward(inputs=list(en.parameters()))\n",
    "    \n",
    "    rtl = loss.item()\n",
    "\n",
    "    print(eidx, rtl)\n",
    "\n",
    "    for p in opt.param_groups:\n",
    "        if rtl < 0.0007:\n",
    "            p[\"lr\"] = 1e-4\n",
    "        elif rtl < 0.005:\n",
    "            p[\"lr\"] = 3e-3\n",
    "        else:\n",
    "            p[\"lr\"] = 4e-3\n",
    "\n",
    "    opt.step()\n",
    "    \n",
    "    eidx += 1\n",
    "# In loop: train like usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: experiment where we take the on-policy CPN outputs,\n",
    "#       similar CPN outputs, and random CPN outputs, and compare grads\n",
    "#       between the EN and backprop-through-the-brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "749d7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.023088084533810616\n",
      "1 0.02138981781899929\n",
      "2 0.019765663892030716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-be18cc2f1e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mrtl\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     _, stim_params, actuals_vec, _ = forward(cpn, din, trial_end, dout, labels,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                          en=en)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-2dfcdbb5c30e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cpn, din, trial_end, dout, labels, en)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtidx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Observe current activity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mobs_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserver_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_raw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrial_end\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtidx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/co-proc/coproc-poc/experiment/mRNN.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, obs_model, drop_module_idx)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_neurons_per_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             ]\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0;31m# aka (batch_size, out_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/co-proc/coproc-poc/experiment/observer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/co-proc/coproc-poc/experiment/observer.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/co-proc/coproc-poc/experiment/observer.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Note: weights may broadcast up if we have batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mreduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = AdamW(cpn.parameters())\n",
    "\n",
    "rtl = 1\n",
    "eidx = 0\n",
    "\n",
    "while rtl > 0.0003:\n",
    "    _, stim_params, actuals_vec, _ = forward(cpn, din, trial_end, dout, labels,\n",
    "                                         en=None)\n",
    "    \n",
    "    actuals = torch.cat(actuals_vec, axis=1)\n",
    "    actuals = utils.trunc_to_trial_end(actuals, trial_end[:, :-1, :])\n",
    "    loss = torch.nn.MSELoss()(actuals, dout[:, 1:, :])\n",
    "    loss.backward(inputs=list(cpn.parameters()))\n",
    "    \n",
    "    rtl = loss.item()\n",
    "    \n",
    "    print(eidx, rtl)\n",
    "\n",
    "    lr_sched(opt, rtl, eidx)\n",
    "    opt.step()\n",
    "    \n",
    "    eidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a partially trained CPN. Let's repeat the experiment here, starting with a new EN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, far later in training, we make another EN and compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6376b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
