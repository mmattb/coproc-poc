%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    INSTITUTE OF PHYSICS PUBLISHING                                   %
%                                                                      %
%   `Preparing an article for publication in an Institute of Physics   %
%    Publishing journal using LaTeX'                                   %
%                                                                      %
%    LaTeX source code `ioplau2e.tex' used to generate `author         %
%    guidelines', the documentation explaining and demonstrating use   %
%    of the Institute of Physics Publishing LaTeX preprint files       %
%    `iopart.cls, iopart12.clo and iopart10.clo'.                      %
%                                                                      %
%    `ioplau2e.tex' itself uses LaTeX with `iopart.cls'                %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
% First we have a character check
%
% ! exclamation mark    " double quote  
% # hash                ` opening quote (grave)
% & ampersand           ' closing quote (acute)
% $ dollar              % percent       
% ( open parenthesis    ) close paren.  
% - hyphen              = equals sign
% | vertical bar        ~ tilde         
% @ at sign             _ underscore
% { open curly brace    } close curly   
% [ open square         ] close square bracket
% + plus sign           ; semi-colon    
% * asterisk            : colon
% < open angle bracket  > close angle   
% , comma               . full stop
% ? question mark       / forward slash 
% \ backslash           ^ circumflex
%
% ABCDEFGHIJKLMNOPQRSTUVWXYZ 
% abcdefghijklmnopqrstuvwxyz 
% 1234567890
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\documentclass[12pt]{iopart}
\usepackage{graphicx}
\graphicspath{ {./figs/} }
%Uncomment next line if AMS fonts required
%\usepackage{iopams}
\begin{document}

\title[Modeling a Neural Co-Processor]
{Towards a Neural Co-Processor Which Restores Movement After Stroke: Modeling a Proof-of-Concept}

\author{Matthew J Bryan$^{1}$, Linxing Preston Jiang$^{1}$, Rajesh P N Rao$^{1}$}

\address{$^{1}$ Neural Systems Laboratory, Department of Computer
Science and Engineering, University of Washington, Box 352350,
Seattle, WA 98105, USA}

\ead{matthew.bryan@dell.com}
\vspace{10pt}
\begin{indented}
\item[]September 2021
\end{indented}

\begin{abstract}
\textit{Objective} Brain co-processors\cite{rao.coproc} are devices which use artificial
intelligence (AI) for closed-loop neurostimulation, to shape neural activity and to bridge
injured neural circuits for targeted repair and rehabilitation. The co-processor framework
offers a flexible approach to learning closed-loop stimulation policies that optimize for
(a) specific regimes of neural activity, or (b) external task performance.
For example, it may seek to learn to stimulate the motor cortex of a stroke patient,
conditioning the stimulation on upstream visual information, aiding the patient's
attempt to grasp an object. Through the use of artificial neural
networks (ANNs) and deep learning, the co-processor co-adapts with the
neural circuit, allowing it to seek optimal stimulation policies, and adapt them
as the neural circuit changes. The results presented here demonstrate a
neural co-processor for the first time, through the use of a simulation. We
explore some of the core algorithms that may allow co-processors to successfully
learn and to adapt to non-stationarity in both the brain and sensors.
\textit{Approach} We provide the first proof-of-concept of a neural co-processor that
leverages deep learning, through the use of a simulated neural circuit
That circuit performs reach-to-grasp task, based on visual input, and is designed to
closely resemble a similar circuit in a primate brain \cite{michaels.mrnn}. We simulate
a variety of lesions by altering the model, and then demonstrate a co-processor's ability
to restore lost function through ``stimulation'' of that model. We further test the
ability of a co-processor to adapt its stimulation as the simulated brain undergoes changes.
\textit{Main results} Our simulated co-processor successfully co-adapts with the neural
circuit to accomplish the external reaching task. The co-processor framework
demonstrated here adapts to a variety of lesion types, and to ongoing changes in the
simulated brain.
\textit{Significance} The proof-of-concept here outlines a co-processor model, as well
as our approach to training it, leading to insights on how such a model may be
developed for \textit{in vivo} use. We believe this co-processor design will allow for
learning complex stimulation policies that help restore function to a stroke victim.
\end{abstract}

\vspace{2pc}
\noindent{\it Keywords}: brain-computer interface, neural co-processor, ai, machine learning, stimulation
%
% Uncomment for Submitted to journal title message
%\submitto{\JPA}
%
% Uncomment if a separate title page is required
\maketitle
% 
% For two-column output uncomment the next line and choose [10pt] rather than [12pt] in the \documentclass declaration
%\ioptwocol
%



\section{Introduction}
Aided in part by application of advanced AI techniques, brain-computer interfaces (BCIs) have made
advancements over the last several decads, allowing for decoded brain signals to be used for
control of a wide variety of virtual and physical prostheses \cite{rao.bcibook, wolpaw.bcibook,
moritz.neuro, lebedev.bmi}. Separately: advances in stimulation techniques and modeling have allowed
us to probe neural circuit dynamics (e.g. \cite{walker.inception}) and learn to better drive neural
circuits towards target dynamics, by encoding and delivering information through
stimulation \cite{niparko.cochlear, weiland.retinal, tomlinson.propr, tabot.tact, tyler.tact,
dadarlat.tact, sharlene.tact, cronin.tact}.
Recently, there has been increasing interest in building on these advances to combine decoding
and encoding in a single system, for closed-loop stimulation of a neural circuit. Bi-directional
BCIs (BBCIs) allow stimulation to be conditioned by decoded brain activity as well as external
sensor data (e.g. camera), which can allow for the application of real-time, fine-grained control of
neural circuits and prosthetic devices, e.g. Nicolelis et al. \cite{nicolelis.bmbi}. These may lead,
for example, to neuro-prostheses that are capable of restoring movement which was lost due to
traumatic brain injury (TBI), to a degree not previously possible.

Motivated by that progress, we demonstrate here a flexible framework for combining encoding
and decoding, which we term ``neural co-processors'' \cite{rao.coproc}. Neural co-processors leverage
AI and deep learning to identify optimal, closed-loop stimulation patterns. The approach is flexible
enough to optimize not only for particular neural activities, but also for tasks external to the
subject. For example, they may be able to aid a stroke victim by finding a stimulation pattern of
the motor cortex which helps restore lost limb function. Likewise, the framework generalizes enough
to condition stimulation on both brain activity, and external sensors, e.g. cameras or LIDAR, in
order to incorporate feedback for realtime control.

Additionally, the co-processor framework allows a neuro-prosthesis to actively adapt to
a neural circuit as it changes with time. This framework is capable of co-adapting with
the circuit, i.e. brain, by updating its stimulation regime, while at the same time the
brain is updating its response to the stimulation, and changing due to natural plasticity,
aging, etc. This allows the co-processor to continually optimize for the intended cost
function, despite the signficant non-stationarity of the target circuit.

Here we provide a proof-of-concept in simulation for a co-processor that restores
movement to a limb, after a subject has suffered a stroke affecting its ability to
use that limb. It combines:
\begin{itemize}
	\item A stimulation model, which models the relationship between decoded brain activity,
	      stimulation, and task performance.
	\item An AI agent which determines the stimulation to apply in a closed-loop fashion, in real time.
\end{itemize}

Significant advances have been made in modeling the effects of electrical stimulation
of the brain, some of which can be leveraged for our co-processor design, as we outline
below. Researchers have explored how information can be biomimetically or
artificially encoded and delivered via stimulation to neuronal networks in the brain and
other regions of the nervous system for auditory \cite{niparko.cochlear}, visual \cite{weiland.retinal},
proprioceptive \cite{tomlinson.propr}, and tactile
\cite{tabot.tact, tyler.tact, dadarlat.tact, sharlene.tact, cronin.tact} perception.
Advancements have also been made in modeling the effects of stimulation over large scale, multi-region
networks, and across time \cite{shanechi.stimmodel}. Some have additionally designed models which
can adapt to ongoing changes in the brain, including changes due to the stimulation itself
\cite{tafazoli.acls}. In our proof-of-concept outlined below, we will use a stimulation
model, not unlike those cited here, which seeks to account for both network dynamics
and non-stationarity. In addition to training the model to have a strong ability to predict
the effect of stimulation, we additionally train it to be useful for then learning an
optimal stimulation policy, which is a property somewhat distinct from predictive
power alone.

Advances have also been made in both open- and closed-loop stimulation for
treating a variety of disorders. Open loop stimulation has been effective in
treating Parkinson's Disease \cite{benabid.parkinsons}, as well as various
psychiatric disorders \cite{holtzheimer.psy, kisely.psy, fraint.psy}.
More directly related to this paper, we see in Khanna et al. \cite{khanna.openloop},
the use of open loop stimulation in restoring dexterity after a lesion
occurs affecting a primate's motor cortex. The authors demonstrate that
the use of low-frequency alternating current, applied epidurally and set to
certain phases, can improve grasp performance.

While open loop stimulation techniques have yielded clinically useful results,
their results in many domains have been mixed, such as use in visual
prostheses \cite{bosking.visual}, and use in invoking somatosensory feedback
\cite{cronin.tact}. Likely this is due to the stimulation not being conditioned
on the ongoing dynamics of the circuit being stimulated. Moment-to-moment and
throughout the day, the circuit will respond differently to the same stimulus,
as a result of differing inputs and ongoing activity. Stimulation
therefore needs to be proactively adapted in response. This need is even
greater over longer time scales as the effects of plasticity and ageing change
the connectivity of the brain.

Closed-loop stimulation conditions stimulation on observations of brain activity,
possibly allowing it to shape the neural activity more precisely, and to adapt to changes
in the circuit over time. This opens the door to real-time, targeted control of the neural
circuit. It has been used to aid in learning new memories after some impairment
\cite{berger.closedloop, kahana.biomarker}, to replay visually-invoked
activations \cite{tafazoli.acls}, and for optogenetic control of
a thalamocortical circuit \cite{bolus.opto}, among others.

Something that remains unclear is how to leverage closed-loop control for real-time
co-adaption with the brain to accomplish an external task. ``Co-adaption'' here refers
to the ability of a neuro-prosthesis to adapt its stimulation regime to the ongoing
changes in the circuit it is stimulating, and to adapt with that circuit to accomplish
the external task, such as grasping. The neural co-processor we present here provides one
potential model for accomplishing that. Through the use of deep learning, the
co-processor model we present co-adapts an AI agent, which governs the
stimulation, with both a stimulation model, and the neural circuit being stimulated.

For a neurologically complex task such as grasping, we cannot identify
\textit{a priori} a real time controller of the neural circuit. That is
due in large part to the variability of circuits from subject-to-subject,
as well as variations in the placement of sensors and stimulators in the
brain. The only plausible path to such a real time controller is to parameterize
it in a subject- and time-specific way. Our model seeks to accomplish that using
deep learning, together with a data-efficient approach to training.

Before attempting \textit{in vivo} experiments using such a model, we first demonstrate
here a number of crucial design elements of it, through the use of a simulated
grasping circuit, presented previously by Michaels et al. \cite{michaels.mrnn}. We
explore:
\begin{itemize}
	\item The properties of the artificial neural networks (ANNs) that are needed to
	      successfully adapt to the long-running dynamics of a stimulated neural circuit,
	      as well as to adapt to that circuit's ongoing changes.
	\item Data-efficient methods for training these models, to better ensure we
	      can train them with a biologically-realistic amount of data.
	\item How we must train our stimulation model to make it effective in later
	      training our stimulation agent.
\end{itemize}

\section{Method}

\begin{figure}
\includegraphics[width=\textwidth]{weill_arch.png}
\caption{Using a co-processor to drive external task performance after a traumatic brain injury}
\centering
\label{fig:weill}
\end{figure}

\subsection{Architecture Overview}
First, we present the architecture of our co-processor design. This design aims to solve two
fundamental challenges in using neural stimulation to improve external task performance.
First, neural networks exhibit long-running and nonlinear dependencies, necessitating
the need for a stimulation agent to account for far-distant effects of the stimulation it
applies. Second, with neurologically complex tasks, such as grasping, the mapping between
neural activity as-measured and the external task cannot be determined \textit{a priori}.
As a result, the co-processor must somehow learn what stimulation is appropriate for
aiding the user in the external task they are attempting to perform.

Our co-processor attempts to solve these with a pair of artificial neural networks:
\begin{itemize}
	\item A stimulation and neural dynamics model, known as an ``Emulator Network'' (EN). It models the relationship
	      between the stimulation, neural dynamics, and external task. It's purpose is for training the second network.
	\item A stimulation agent, known as the ``co-processor network'' (CPN), which maps neural activity, and possibly
	      data from external sensors, to stimulation parameters.
\end{itemize}

We co-train the EN and CPN, with the goal of training a CPN whose output stimulation parameters
improve task performance. By continually training both, they adapt to the brain as it changes,
effectively allowing for brain-stimulator co-adaptation. The EN is a tool for training the CPN,
giving us a way to back-propagate task error to the CPN. It outputs task-relevant
metrics - a prediction of muscle velocities in our case - given measurements of neural
activity, and the stimulation parameters output from the CPN. If the EN is trained in a
particular way, and to a sufficient level of precision, it can be used as a function
approximator relating stimulation and a task, and do so in a way that allows us to train
the CPN with it. When training the CPN, we in-effect treat the EN's output as the true
task performance, or a related metric, and then backpropagate the loss defined in terms
of that metric in order to train the CPN. See Fig. \ref{fig:weill}. We will illustrate the details
of the training algorithm below.

In our present demonstration, the EN is constituted as a single layer, fully connected,
long short-term memory (LSTM) recurrent neural network (RNN), with hyperbolic tangent ($tanh$)
activations, and a linear readout. The general notion of a co-processor does
not require this precise architecture, but for our example, we found that the LSTM
approach allows the network to continuously adapt to long-running dependencies in
the simulated neural dynamics, far better than a vanilla RNN. The CPN is constituted
as an almost identical network, though with a different dimensionality, as we explain
below. There is no strict requirement for the EN and CPN to be so similar, but we
found this simple architecture to work well in our example.

Note that the EN effectively constitutes a stimulation model. Its design is
somewhat motivated by the common linear time-invariant state space model of
stimulation, as in e.g. Yang et al. \cite{shanechi.stimmodel}, which is a helpfully
simple (linear) approach. That approach seeks to model neural network dynamics in
terms of a stationary linear model, which, due in part to its simplicity and the
number of techniques developed for it, lends itself to useful interpretations and
analyses of those neural dynamics.

There are some key differences between that approach and the EN architecture we
present here. Our EN's purpose is simply to train the CPN, so we pick an
architecture we find to be best suited to that job. First, our EN architecture
is not linear, through the use of a $tanh$ activation function. That allows us
to escape some of the limits in representational power of linear models, though
we didn't deeply test a strictly linear approach.
Second, LSTM cells are designed to better capture long-running network
dynamics, and in our case we found that they were crucial for that reason:
when using vanilla RNN cells, our co-processor wasn't able to train well.
Compare that to the simpler cells commonly used in vanilla RNNs, which
yield functionally the same approach as the linear state space model, less
the use of a nonlinear activation function.

\subsection{Simulation Overview}
We demonstrate our approach here using a simulated grasping circuit.
A detailed simulation such as this allows us to explore some of the critical details in
training a co-processor of this design. By first doing such exploration in
simulation, we are able to rapidly and cheaply iterate on our design, prior to
any \textit{in vivo} experiments. In order for the simulation to be
admissible, we need to ensure it has some properties that allow it to strongly
indicate if our design is improving in a direction that will later allow for
real deployments. Otherwise, our design may be adapting to the pecularities of
the simulation, without becoming more useful for the real world.

The simulated circuit, from Michaels et al. \cite{michaels.mrnn, susillo.mrnn}, was trained
to resemble the grasping circuits of monkey subjects engaged in a reach-to-grasp task. It
consists of a ``modular'' vanilla RNN, and a linear readout layer. The inputs are visual
features intended to capture the view the monkeys had during the task, i.e. 3D renderings of
the same objects which the monkeys grasped. The outputs are muscle length velocities for the
should, arm, and hand of the monkey during the trial. The natural velocities were captured
with a motion capturing glove, and the artificial neural network is trained to recapitulate
those grasping motions. See Fig. \ref{fig:michaels}.

The design of the circuit is intended to resemble a vision-to-grasp pipeline, essentially
representing the visual processing needed to reach the hand to the appropriate position for
the grasp, and to form the hand properly for grasping the particular shape of object. The
emergent dynamics of the artificial network's ``modules'', once train, correspond roughly
to the AIP, F5, and M1 portions of the monkey subjects' brains. Notably, the activity of
the module receiving the visual inputs resembles the AIP activity of the monkey subject
from the same trials. Likewise, the second and third modules resemble the natural activity
from the monkey's F5 and M1 regions, respectively. The network dynamics show a number of
other correspondences to the monkeys' natural brain activity as well, as detailed in the paper.

Notably, the simulated circuit's activity shows a relatively clear separation of the
object shapes.  That is - the visual information input to the network differentiates one trial
from another, and the circuit is able to leverage that information to properly condition
the hand shape trajectory for grasping the object of that trial's particular shape, size, and location.
The visual information forward-propagates through the network, through successive processing
steps, where it is eventually leveraged to recapitulate the grasp appropriate for the object
represented by the input visual features. As we will note below: in the absense of this
visual information forward propagating, the circuit can at-best learn a loss-minimizing grasp,
stereotyped across all object sizes and shapes. Such a grasp bears some resemblance to all
grasps the given monkey performed, due to all trials being a reach-to-grasp preceded by a
waiting period, but performance suffers drastically.

As a result, simulating a brain lesion in terms of this artificial network results in error modes
which resemble a natural lesion of certain regions of a primate brain.

...
* Lesioning properties

* Long-running dynamics


** Potentially helpful to look for a simulated neural circuit which has internal dynamics, i.e. information propagation, which is demonstrably similar to natural circuits.
** \cite{kao.sim} Likeness of RNNs to natural circuits re: dynamics
** Cite Michaels, and those upstream from him (Susillo?) re: RNNs. Networks have internal dynamics that result from both inputs and internal connectivity. Perturbations at t=0 affect outputs at t=N.
** \cite{bernal.sim} Simulation of spiking neural network, learning stimulation regime. Use of a biomimetic
  simulation to develop and evaluate a neural controller. Use of lesion model.

Example: Use of actual stimulation of an actual brain, together with offline deep learning,
to search for an optimal visual input: \cite{walker.inception}

* Overview of test bed
** Michaels model .
** Lesion designs
*** Lesion examples, i.e. hand velocity more affected than shoulder velocity.
*** Disconnect modules vs lesion M1, and the effects
** Stimulation design
*** Spatio-temporal smoothing
** Observation model

* Overview of the four experiments:
** Vanilla
** Co-adaptive with connectivity loss
** Co-adaptive with partial M1 loss
** Co-adaptive with data reuse

\subsection{Training the Model}
Training
** Alternate training EN and CPN
*** Train an EN
**** Training the EN until predictive power reaches a threshold, based on current task performance
**** Training regime based on most recent CPN, similar CPNS (noise added to params), and white noise stimulation
**** Single batch of data from applying current CPN set and white noise to the brain, EN fit to ``offline'' it over maining epochs
**** Predictive power alone is not sufficient for use in training the CPN: we need to form the batch as above, otherwise training is unstable.
*** Train the CPN
**** Backprop through the EN, effectively using the EN's prediction as ground truth

\section{Results}

* Task performance improves drastically
* Fine tuning takes a long time
* Object classes separate
* Can co-adapt with the brain, as it changes

* Split by lesion design

* Show example where AIP/F5 lesioned and how that affects performance

* Any point in showing sensitivity to observation or stim dim?

* Try regularization variation?

* White noise and noised params
** Learning instability
** Predictive power isn't enough
** Illustrate this

* Training efficiency analysis

\section{Discussion}
* Training efficiency
* Spectrum from simple low dimensional stimulation vectors today to higher dimensional future
* Toward in vivo application

\section{Conclusion}
asdf

\section{Acknowledgements}
Ganguly, Priya, Anca, Justin, Luciano

\section{Ethical Statement}
asdf

\section{References}
\bibliographystyle{iopart-num}
\bibliography{refs}
\end{document}

